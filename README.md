# Custom YOLOv5s Quantization and Compilation using VAI 2.0 and Inference on UltraZed EV FPGA

## Project Overview
This repository contains all necessary files and documentation for deploying a custom-trained YOLOv5 model on an FPGA using the Vitis AI 2.0 framework. The model is designed for **fire detection**, trained on a custom dataset sourced from **Roboflow**. The end-to-end process—from model training to FPGA inference—is documented in detail.

---

## Repository Contents

| File/Folder | Description |
|--------------|-------------|
| **CustomYolo.ipynb** | Jupyter Notebook used for training the custom YOLOv5 model on the fire dataset. |
| **Project Documentation.docx** | Step-by-step project documentation covering all phases from Petalinux setup to FPGA inference. |
| **README.md** | Initial repository documentation. |
| **best.pt** | The trained YOLOv5 model checkpoint generated after training on the custom fire dataset. |
| **codes run on fpga.zip** | Contains all Python scripts and resources required to run inference on the FPGA board. |
| **codes to run on vitis ai.zip** | Includes scripts and configuration files to be used within the Vitis AI Docker environment. |
| **model generated by vitis ai.zip** | Contains the compiled `.xmodel` and other files generated during model quantization and compilation in Vitis AI. |
| **yolov5s.pt** | The base YOLOv5 small (S) model checkpoint used for training initialization. |
| **yolov5s.yaml** | The model configuration file specifying the YOLOv5S architecture and parameters. |

---

## Project Workflow

The project is organized into **five main sections**, as detailed in the project documentation:

1. **Create and Build Petalinux for the FPGA**  
   - Set up and build the Petalinux environment for the target FPGA board.

2. **Vitis AI Docker Installation and Setup**  
   - Install and configure the Vitis AI Docker environment compatible with the FPGA and model compilation tools.

3. **Quantize and Compile `best.pt` Using Vitis AI**  
   - Quantize the YOLOv5 model from FP32 to INT8 using the Vitis AI quantizer and compile it to generate the `.xmodel` file.

4. **Boot FPGA, Transfer Required Code Files, and Test Data**  
   - Boot the FPGA board, transfer inference scripts, test images, and videos to the appropriate directories.

5. **Run Inference on FPGA**  
   - Execute the inference scripts on the FPGA to evaluate model performance on real-world fire detection data.

---

## Dataset Information

The dataset is **not included in this repository**.  
However, the **first code snippet** in the `CustomYolo.ipynb` notebook downloads the dataset automatically from Roboflow.

---

## Important Notes

- The provided model (`best.pt`) yields **suboptimal results** because it was trained on only **525 images** using the **YOLOv5-S** architecture and later quantized from **FP32 to INT8**.  
  This limited training data results in lower inference accuracy.

- To improve results:
  - Replace `best.pt` with a **better-trained YOLOv5 model**.
  - Re-run the quantization and compilation process inside the **Vitis AI Docker** environment.
  - Ensure the entire YOLO directory, including the `runs` folder and the `.pt` model file, is transferred into the Vitis AI Docker container for proper quantization.

---

## Python Compatibility Fix

The **Vitis AI 2.0** environment supports **Python ≤ 3.8**.  
To avoid runtime errors due to newer Python syntax, particularly the **walrus operator (`:=`)**, modify the code as follows:

### Unsupported (Python ≥3.9 Syntax)
```python
if len := k
```
### Compatible (Python ≤3.8 Syntax)
```python
len = k
if len:
```

